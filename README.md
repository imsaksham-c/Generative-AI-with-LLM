# Generative AI with Large Language Models

The transformative impact of the transformers architecture, introduced in 2017 through the influential "Attention is All You Need" paper, has reshaped the landscape of generative AI.

These are comprehensive course notes from the "Generative AI with LLM" course on Coursera, jointly offered by AWS and deeplearning.ai. The course delves into the intricacies of the generative AI project lifecycle, breaking it down into five distinct stages.

ğŸ“š **What's Inside?**

ğŸš€ **PART 1: LLM Pre-Training**

- Understanding Large Language Models (LLMs)
- Real-world Use Cases for LLM Applications
- Evolution from Pre-Transformers to Transformers
- Mechanisms of Text Generation in Transformers
- Significance of Prompts in the Generation Process
- Deep Dive into the Generative AI Project Life Cycle
- Navigating Challenges in Pre-Training LLMs
- Optimal Configurations for Effective LLM Pre-Training
- When and Why Pre-Training LLMs Is Beneficial

ğŸ’¡ **PART 2: LLM Fine Tuning**

- Insights into Instruction Fine Tuning
- Addressing Catastrophic Forgetting in Fine Tuning
- Evaluation Criteria for Fine-Tuned Models
- Unpacking Parameter Efficient Fine Tuning (PEFT)

ğŸŒ **PART 3: RLHF & Application**

- Aligning AI Models with Human Values
- Fundamentals of Reinforcement Learning from Human Feedback (RLHF)
- Strategies to Mitigate Reward Hacking
- Scalability through Self-Supervision with Constitutional AI
- Optimization and Deployment of LLMs for Inferencing
- Practical Implementation in Various Applications
- Architecture Considerations for LLM Applications
- Embracing Responsible AI Practices
- Handy Cheatsheet for the Generative AI Project Lifecycle

ğŸ’» **Code and Assignments**

The [code directory](/code) includes detailed examples for three coding assignments:

- `Summerize-Dialogue.ipynb`: Assignment covering Prompt Engineering.
- `Fine-Tuning Lab.ipynb`: Assignment covering Instruction Fine-Tuning using LoRA.
- `RLHF Lab.ipynb`: Assignment covering Reinforcement Learning From Human Feedback to align LLMs.

ğŸ“ **Course Certificate**

![Course Certificate](https://github.com/imsaksham-c/Generative-AI-with-LLM/blob/main/coursera.jpg)

Feel free to explore the code and resources to enhance your understanding of Generative AI with Large Language Models! ğŸš€
